import re
import itertools
import datetime
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer

import database, l1_login


personality_features_pre = np.array(pd.read_excel('/Users/takipon/Desktop/dprapp/sample.xlsx', index_col=0, header=0, sheet_name='personality_x2').columns)
personality_features = np.delete(np.delete(personality_features_pre, 28), 27)





#å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
ip = l1_login.get_ip().pop()
personality_pre = np.array(database.l2_personality_last_record(ip))
personality_num = np.ravel(personality_pre)[2] #[1 0 1 1 1 0 0 0 1 1 1 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1]
personality_num = personality_num.translate(str.maketrans({' ':'', '[':'', ']':''})) #101110001110101010010001101

all_personality_record_pre= np.array(database.l2_personality_all_record())
all_personality_record = pd.DataFrame(all_personality_record_pre).iloc[:, 2] #0~79 [1 0 1 1 1 0 0 0 1 1 1 0 1 0 1 0 1 0 0 1 0 0 0...



#å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° åŒã˜æ€§æ ¼
similarity_rate=[]
for num in range(len(all_personality_record)):

    x_personality_num = all_personality_record[num].translate(str.maketrans({' ':'', '[':'', ']':''})) #101110001110101010010001101

    common_features = []
    for i in range(len(personality_features)):
        if personality_num[i] == x_personality_num[i]:
            common_features.append(personality_features[i]) #ä¸¡è€…ã®å…±é€šã™ã‚‹æ€§æ ¼ã‚’æ¢ã™

    if len(common_features) / len(personality_features) >= 0.7: #19/27=70%å…±é³´ #ğŸŒŸæœ¬ç•ªã§ã¯0.8ã«
        similarity_rate.append(num) #æ€§æ ¼ãŒä¼¼ã¦ã‚‹äººãŸã¡ã®é…åˆ—ç•ªå·ãŒå…¥ã£ã¦ã‚‹



#å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° åŒã˜ç›®æ¨™
def word_cut(x):

    vect = CountVectorizer(stop_words='english').fit(x)
    vect.transform(x)
    words = vect.get_feature_names()
    return words


user_end_goal_pre = database.l2_endg_show(ip)
user_endg_task_pre = list(itertools.chain.from_iterable(user_end_goal_pre))[3].split(',') #[' build better relationships.', " work on goals you've given up on", 'Travel', '']
user_endg_task = word_cut(user_endg_task_pre) #['better', 'build', 'given', 'goals', 'relationships', 'travel', 've', 'work']


tips_list = []
end_goal_list = []
for num in similarity_rate:

    other_user_ip = all_personality_record_pre[num][1] #æ€§æ ¼ä¼¼ã¦ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ipç²å¾—

    # other_users_end_goal_pre = database.l2_endg_show(other_user_ip)#ğŸŒŸæœ¬ç•ªã§ã¯ã“ã£ã¡
    # other_users_endg_pre = list(itertools.chain.from_iterable(other_users_end_goal_pre))[3].split(',') #ğŸŒŸæœ¬ç•ªã§ã¯ã“ã£ã¡#[' build better relationships.', " work on goals you've given up on", 'Travel', '']
    # other_user_endg_task = word_cut(other_users_endg_pre) #['better', 'build', 'given', 'goals', 'relationships', 'travel', 've', 'work'] #ğŸŒŸæœ¬ç•ªã§ã¯ã“ã£ã¡
    other_user_endg_task = ['better', 'build', 'BTS', 'sweden', 'relationships', 'programmer', 've', 'work','21'] 

    tips = []
    for x in user_endg_task:
        for i in other_user_endg_task:
            if x == i:
                tips.append(1)
            else:
                tips.append(0)
    tips_list.append(tips)

similarity_rate_endg = []
for num in range(len(tips_list)): #01ã‚»ãƒƒãƒˆãŸã¡ã®å€‹æ•°
    if sum(tips_list[num]) / len(user_endg_task) >= 0.6: #ğŸŒŸæœ¬ç•ªã§ã¯0.8
        similarity_rate_endg.append(similarity_rate[num]) #åŒã˜ç›®æ¨™ã‚’æŒã£ã¦ã‚‹äººãŸã¡ã®é…åˆ—ç•ªå·ãŒå…¥ã£ã¦ã‚‹





#LDA 
other_user_txt_bbs = []
other_user_act_bbs = []
for num in similarity_rate_endg:
    other_user_ip = all_personality_record_pre[num][1]
    other_user_dairy = np.array(database.l2_dairy_show(other_user_ip))

    mind = int(other_user_dairy[0][2]) #1ã¤ç›®ã‚’å–å¾—

    for next_mind in other_user_dairy: #2ã¤ç›®ã‹ã‚‰ã—ãŸã„ã‘ã©ã€ä½™è¨ˆãªã‚³ãƒ¼ãƒ‰ãŒå¢—ãˆã‚‹ã®ã§ã‚¹ãƒ«ãƒ¼
        if int(next_mind[2]) > mind: #ğŸŒŸæœ¬ç•ªã¯>=ã§ã¯ãªã>ã®ã¿
            x_day = (next_mind[4] - mind_datetime).days #æ•°å€¤ä¸Šæ˜‡å‰æ—¥-æ•°å€¤ä¸Šæ˜‡æ—¥ã€‚ä½•æ—¥ã‹ã®ã¿å–å¾—ã€æ™‚é–“åˆ‡ã‚Šæ¨ã¦
            
            for day in range(x_day):
                # add_day = mind_datetime + datetime.timedelta(days=day) #æ•°å€¤ä¸Šæ˜‡å‰æ—¥ã‹ã‚‰ï¼‘æ—¥ãšã¤è¿½åŠ  ğŸŒŸæœ¬ç•ªã§ã¯ã“ã£ã¡
                # add_day = add_day.strftime('%Y-%m-%d') #æ™‚åˆ»ã‚’æ¨ã¦ã‚‹ ğŸŒŸæœ¬ç•ªã§ã¯ã“ã£ã¡
                add_day = '2021-01-07'

                #æ²ç¤ºæ¿ã§ã®ç™ºè¨€å›å
                other_user_txt_bbs_pre = np.array(database.l3_bbs_txt_show_date(add_day))
                if len(other_user_txt_bbs_pre) != 0: #æ²ç¤ºæ¿ã§ã®ç™ºè¨€ãŒã‚ã£ãŸã‚‰
                    for num in other_user_txt_bbs_pre:
                        other_user_txt_bbs.append(num[2]) #æ²ç¤ºæ¿ã§ã®ç™ºè¨€ã‚’å›å

                #æ²ç¤ºæ¿ã§ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å›å ã‚¢ã‚¯ã‚·ãƒ§ãƒ³â†’ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã—ãŸidâ†’æ²ç¤ºæ¿ã§ã®ç™ºè¨€id
                other_user_act_bbs_pre = np.array(database.l3_bbs_act_show_date(add_day))
                if len(other_user_act_bbs_pre) != 0: #æ²ç¤ºæ¿ã§ã®è¡Œå‹•ãŒã‚ã£ãŸã‚‰
                    for num in other_user_act_bbs_pre:
                        bbs_txt_pre = np.array(database.l3_bbs_txt_show_id(num[2]))
                        bbs_txt = np.ravel(bbs_txt_pre)
                        other_user_act_bbs.append(bbs_txt[2]) #æ²ç¤ºæ¿ã§ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å›å

        mind_datetime = next_mind[4]
        mind = int(next_mind[2])

    break #ğŸŒŸæœ¬ç•ªã§ã¯ã“ã‚Œã‚’è§£é™¤ å¤§é‡ã«ä¼¼ã¦ã‚‹äººãŒã„ã‚‹ã®ã§æ¼”ç®—ãŒé•·ããªã‚Šã†ã–ã„

act_bbs = word_cut(other_user_act_bbs)
txt_bbs = word_cut(other_user_txt_bbs)





#LSTM(RNN)
