{%- extends "layout.html" %}
{%- block content %}


<div class="large" style='margin-top: 30px;'>
    <div class="text-center">

        {% for i in range(fgs|length) %}
            <div style="color: rgb(94, 110, 255);">
                <input type="checkbox" name="q1" data-question="{{i}}" class="question_checkbox"> {{fgs[i]}}
            </div>        
        {% endfor %}

        <ul class="vertical menu" data-accordion-menu>
            <li>
                <a href="#0">This is the code for a feature that could not be used due to heroku's slug size issue.</a>
                <ul class="menu vertical nested">
                  <li>
                      <textarea style="height: 500px;">
                        import re
                        import os 
                        import time
                        import itertools
                        import datetime
                        import random
                        import numpy as np
                        import pandas as pd
                        from sklearn.feature_extraction.text import CountVectorizer
                        from keras.models import Sequential
                        from keras.layers import Dense, LSTM
                        
                        import database, l1_login
                        
                        
                        personality_features_pre = np.array(pd.read_excel('/Users/takipon/Desktop/dprapp/sample.xlsx', index_col=0, header=0, sheet_name='personality_x2').columns)
                        personality_features = np.delete(np.delete(personality_features_pre, 28), 27)
                        
                        
                        
                        
                        
                        #LSTM(RNN)
                        class LSTM_RNN:
                        
                            def make_sentense(act_txt_bbs):
                        
                                #„ÉÜ„Ç≠„Çπ„Éà„Éá„Éº„Çø„ÅÆÂâçÂá¶ÁêÜ
                                os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'
                                start = time.time()
                        
                                text_pre = pd.read_excel('/Users/takipon/Desktop/dprapp/sample.xlsx', index_col=None, header=0, sheet_name='sugesstion_list')
                                all_text = text_pre['text']
                                all_text = random.choice(all_text)
                        
                                text = all_text + ' ' + act_txt_bbs + ' . '
                                print("ÊñáÂ≠óÊï∞",text)
                        
                        
                        
                                #LSTMË®≠ÂÆö„Çí„Åô„Çã
                                n_rnn = 10 #ÊôÇÁ≥ªÂàó„ÅÆÊï∞
                                batch_size = 128 
                                epochs = 200 #Â§ö„ÅÑ„Å®Á≤æÂ∫¶„Åå‰∏ä„Åå„Çã„Åå„ÄÅ„É©„Ç∞„ÅÑ„ÅÆ„Åß20„Åß
                                n_mid = 256 #‰∏≠ÈñìÂ±§„ÅÆ„Éã„É•„Éº„É≠„É≥Êï∞
                        
                        
                        
                                #ÊñáÂ≠ó„ÅÆ„Éô„ÇØ„Éà„É´Âåñ
                                # „Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„Å®ÊñáÂ≠ó„ÅßËæûÊõ∏„Çí‰ΩúÊàê
                                chars = sorted(list(set(text)))  # set„ÅßÊñáÂ≠ó„ÅÆÈáçË§á„Çí„Å™„Åè„Åó„ÄÅÂêÑÊñáÂ≠ó„Çí„É™„Çπ„Éà„Å´Ê†ºÁ¥ç„Åô„Çã
                                print("ÊñáÂ≠óÊï∞ÔºàÈáçË§áÁÑ°„ÅóÔºâ", len(chars))
                                char_indices = {}  # ÊñáÂ≠ó„Åå„Ç≠„Éº„Åß„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„ÅåÂÄ§
                                for i, char in enumerate(chars):
                                    char_indices[char] = i
                                indices_char = {}  # „Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„Åå„Ç≠„Éº„ÅßÊñáÂ≠ó„ÅåÂÄ§
                                for i, char in enumerate(chars):
                                    indices_char[i] = char
                                
                                # ÊôÇÁ≥ªÂàó„Éá„Éº„Çø„Å®„ÄÅ„Åù„Çå„Åã„Çâ‰∫àÊ∏¨„Åô„Åπ„ÅçÊñáÂ≠ó„ÇíÂèñ„ÇäÂá∫„Åô
                                time_chars = []
                                next_chars = []
                                for i in range(0, len(text) - n_rnn):
                                    time_chars.append(text[i: i + n_rnn])
                                    next_chars.append(text[i + n_rnn])
                                
                                # ÂÖ•Âäõ„Å®Ê≠£Ëß£„Çíone-hotË°®Áèæ„ÅßË°®„Åô„ÄÇÔºëÊñáÂ≠óÊØé„Å´0,1„ÅÆ„Éô„ÇØ„Éà„É´„Çí„Éï„É´„Ç§„É°„Éº„Ç∏„Åß„Åô„ÄÇ
                                x = np.zeros((len(time_chars), n_rnn, len(chars)), dtype=np.bool)
                                t = np.zeros((len(time_chars), len(chars)), dtype=np.bool)
                                for i, t_cs in enumerate(time_chars):
                                    t[i, char_indices[next_chars[i]]] = 1  # Ê≠£Ëß£„Çíone-hotË°®Áèæ„ÅßË°®„Åô
                                    for j, char in enumerate(t_cs):
                                        x[i, j, char_indices[char]] = 1  # ÂÖ•Âäõ„Çíone-hotË°®Áèæ„ÅßË°®„Åô
                        
                                print("x„ÅÆÂΩ¢Áä∂", x.shape)
                                print("t„ÅÆÂΩ¢Áä∂", t.shape)
                        
                        
                        
                                #LSTM„É¢„Éá„É´„ÅÆÊßãÁØâ
                                model_lstm = Sequential()
                                model_lstm.add(LSTM(n_mid, input_shape=(n_rnn, len(chars))))
                                model_lstm.add(Dense(len(chars), activation="softmax"))
                                model_lstm.compile(loss='categorical_crossentropy', optimizer="adam")
                                print(model_lstm.summary())
                        
                        
                        
                                #ÊñáÁ´†ÁîüÊàêÁî®„ÅÆÈñ¢Êï∞
                                from keras.callbacks import LambdaCallback
                                
                                def on_epoch_end(epoch, logs):
                                    print("„Ç®„Éù„ÉÉ„ÇØ: ", epoch)
                        
                                    elapsed_time = time.time() - start
                                    print ("on_epoch_end  elapsed_time:{0}".format(elapsed_time) + "[sec]")
                                    
                                    beta = 4  # Á¢∫ÁéáÂàÜÂ∏É„ÇíË™øÊï¥„Åô„ÇãÂÆöÊï∞
                                    prev_text = text[0:n_rnn]  # ÂÖ•Âäõ„Å´‰Ωø„ÅÜÊñáÂ≠ó
                                    created_text = prev_text  # ÁîüÊàê„Åï„Çå„Çã„ÉÜ„Ç≠„Çπ„Éà
                                    
                                    print("„Ç∑„Éº„Éâ: ", created_text)
                        
                                    for i in range(100):
                                        # ÂÖ•Âäõ„Çíone-hotË°®Áèæ„Å´
                                        x_pred = np.zeros((1, n_rnn, len(chars)))
                                        for j, char in enumerate(prev_text):
                                            x_pred[0, j, char_indices[char]] = 1
                                        
                                        # ‰∫àÊ∏¨„ÇíË°å„ÅÑ„ÄÅÊ¨°„ÅÆÊñáÂ≠ó„ÇíÂæó„Çã
                                        # y„ÅÆÂΩ¢Áä∂„ÅØ„ÄÅ1Âàó 1049Ë°å(ÊñáÂ≠óÊï∞=Âá∫ÂäõÂ±§„ÅÆÊï∞)„Å´„Å™„Å£„Å¶„ÅÑ„Çã
                                        y = model.predict(x_pred)
                                        #print(y.shape )
                                        p_power = y[0] ** beta  # Á¢∫ÁéáÂàÜÂ∏É„ÅÆË™øÊï¥(1049ÂÄã„ÅÆÈÖçÂàó„ÅÆ‰∏≠„Åã„Çâ„ÄÅÁ¢∫Áéá„ÅåÈ´ò„ÅÑÊñáÂ≠ó„ÇíÂèñÂæó„Åó„Çà„ÅÜ„Å®„Åó„Å¶„ÅÑ„Çã„ÄÄ)
                                        next_index = np.random.choice(len(p_power), p=p_power/np.sum(p_power))        
                                        next_char = indices_char[next_index]
                        
                                        created_text += next_char
                                        prev_text = prev_text[1:] + next_char
                        
                                    print(created_text)
                                    print()
                                    
                        
                        
                                # „Ç®„Éù„ÉÉ„ÇØÁµÇ‰∫ÜÂæå„Å´ÂÆüË°å„Åï„Çå„ÇãÈñ¢Êï∞„ÇíË®≠ÂÆö
                                epock_end_callback= LambdaCallback(on_epoch_end=on_epoch_end)
                        
                        
                        
                                #Â≠¶Áøí
                                model = model_lstm
                        
                                elapsed_time = time.time() - start
                                print ("Â≠¶ÁøíÈñãÂßã elapsed_time:{0}".format(elapsed_time) + "[sec]")
                                history_lstm = model_lstm.fit(x, t,
                                                    batch_size=batch_size,
                                                    epochs=epochs,
                                                    callbacks=[epock_end_callback])
                        
                        
                        
                        
                        
                                # def get_antifical_text(lstm_predict):
                                def get_antifical_text():
                            
                                    beta = 4  # Á¢∫ÁéáÂàÜÂ∏É„ÇíË™øÊï¥„Åô„ÇãÂÆöÊï∞
                                    prev_text = text[0:n_rnn]  # ÂÖ•Âäõ„Å´‰Ωø„ÅÜÊñáÂ≠ó
                                    created_text = prev_text  # ÁîüÊàê„Åï„Çå„Çã„ÉÜ„Ç≠„Çπ„Éà
                        
                                    for i in range(100):
                                        x_pred = np.zeros((1, n_rnn, len(chars)))
                                        for j, char in enumerate(prev_text):
                                            x_pred[0, j, char_indices[char]] = 1
                                            
                                        y = model.predict(x_pred)
                                        p_power = y[0] ** beta  # Á¢∫ÁéáÂàÜÂ∏É„ÅÆË™øÊï¥(1049ÂÄã„ÅÆÈÖçÂàó„ÅÆ‰∏≠„Åã„Çâ„ÄÅÁ¢∫Áéá„ÅåÈ´ò„ÅÑÊñáÂ≠ó„ÇíÂèñÂæó„Åó„Çà„ÅÜ„Å®„Åó„Å¶„ÅÑ„Çã„ÄÄ)
                                        next_index = np.random.choice(len(p_power), p=p_power/np.sum(p_power))        
                                        next_char = indices_char[next_index]
                        
                                        created_text += next_char
                                        prev_text = prev_text[1:] + next_char
                        
                                    return created_text
                        
                        
                                # lstm_predict = model_lstm.predict(x, batch_size=batch_size)
                                # antifical_txt_pre = get_antifical_text(lstm_predict)
                                antifical_txt_pre = get_antifical_text()
                                # print('AIÊñáÁ´†',antifical_txt_pre)
                                antifical_txt = antifical_txt_pre.split()
                                # print(antifical_txt_pre)
                        
                                ai_txt_num = antifical_txt.index('.')
                        
                                #„Ç´„É≥„Éû„Åå„ÅÇ„Çã„Å®„Åì„Çç„Åæ„Åß‰Ωú„Å£„ÅüÊñáÁ´†„ÇíÂçòË™û„ÇíÂÖ•„Çå„Å¶„ÅÑ„Åè
                                ai_txt = ''
                                for num in range(ai_txt_num):
                                    ai_txt = ai_txt + ' ' + antifical_txt[num]
                        
                                return ai_txt
                        
                        
                        
                        
                        
                        #ÂçîË™ø„Éï„Ç£„É´„Çø„É™„É≥„Ç∞ Âêå„ÅòÁõÆÊ®ô
                        def word_cut(x):
                        
                            vect = CountVectorizer(stop_words='english').fit(x)
                            vect.transform(x)
                            words = vect.get_feature_names()
                            return words
                        
                        
                        
                        
                        
                        
                        def suggest():
                            #ÂçîË™ø„Éï„Ç£„É´„Çø„É™„É≥„Ç∞
                            ip = l1_login.get_ip().pop()
                            personality_pre = np.array(database.l2_personality_last_record(ip))
                            personality_num = np.ravel(personality_pre)[2] #[1 0 1 1 1 0 0 0 1 1 1 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1]
                            personality_num = personality_num.translate(str.maketrans({' ':'', '[':'', ']':''})) #101110001110101010010001101
                            print('1', personality_num)
                        
                            all_personality_record_pre= np.array(database.l2_personality_all_record())
                            all_personality_record = pd.DataFrame(all_personality_record_pre).iloc[:, 2] #0~79 [1 0 1 1 1 0 0 0 1 1 1 0 1 0 1 0 1 0 0 1 0 0 0...
                            print('2', all_personality_record)
                        
                        
                        
                            #ÂçîË™ø„Éï„Ç£„É´„Çø„É™„É≥„Ç∞ Âêå„ÅòÊÄßÊ†º
                            similarity_rate=[]
                            for num in range(len(all_personality_record)):
                        
                                x_personality_num = all_personality_record[num].translate(str.maketrans({' ':'', '[':'', ']':''})) #101110001110101010010001101
                        
                                common_features = []
                                for i in range(len(personality_features)):
                                    if personality_num[i] == x_personality_num[i]:
                                        common_features.append(personality_features[i]) #‰∏°ËÄÖ„ÅÆÂÖ±ÈÄö„Åô„ÇãÊÄßÊ†º„ÇíÊé¢„Åô
                        
                                if len(common_features) / len(personality_features) >= 0.7: #19/27=70%ÂÖ±È≥¥ #üåüÊú¨Áï™„Åß„ÅØ0.8„Å´
                                    similarity_rate.append(num) #ÊÄßÊ†º„Åå‰ºº„Å¶„Çã‰∫∫„Åü„Å°„ÅÆÈÖçÂàóÁï™Âè∑„ÅåÂÖ•„Å£„Å¶„Çã
                            print('3', similarity_rate)
                        
                        
                        
                            user_end_goal_pre = database.l2_endg_show(ip)
                            user_endg_task_pre = list(itertools.chain.from_iterable(user_end_goal_pre))[3].split(',') #[' build better relationships.', " work on goals you've given up on", 'Travel', '']
                            user_endg_task = word_cut(user_endg_task_pre) #['better', 'build', 'given', 'goals', 'relationships', 'travel', 've', 'work']
                            print('4', user_endg_task)
                        
                        
                        
                            tips_list = []
                            end_goal_list = []
                            for num in similarity_rate:
                        
                                other_user_ip = all_personality_record_pre[num][1] #ÊÄßÊ†º‰ºº„Å¶„Çã„É¶„Éº„Ç∂„Éº„ÅÆipÁç≤Âæó
                        
                                other_users_end_goal_pre = database.l2_endg_show(other_user_ip)#üåüÊú¨Áï™„Åß„ÅØ„Åì„Å£„Å°
                                other_users_endg_pre = list(itertools.chain.from_iterable(other_users_end_goal_pre))[3].split(',') #üåüÊú¨Áï™„Åß„ÅØ„Åì„Å£„Å°#[' build better relationships.', " work on goals you've given up on", 'Travel', '']
                                other_user_endg_task = word_cut(other_users_endg_pre) #['better', 'build', 'given', 'goals', 'relationships', 'travel', 've', 'work'] #üåüÊú¨Áï™„Åß„ÅØ„Åì„Å£„Å°
                                # other_user_endg_task = ['better', 'build', 'BTS', 'sweden', 'relationships', 'programmer', 've', 'work','21'] 
                                print('5', other_user_endg_task)
                        
                        
                                tips = []
                                for x in user_endg_task:
                                    for i in other_user_endg_task:
                                        if x == i:
                                            tips.append(1)
                                        else:
                                            tips.append(0)
                                tips_list.append(tips)
                        
                            similarity_rate_endg = []
                            for num in range(len(tips_list)): #01„Çª„ÉÉ„Éà„Åü„Å°„ÅÆÂÄãÊï∞
                                if sum(tips_list[num]) / len(user_endg_task) >= 0.6: #üåüÊú¨Áï™„Åß„ÅØ0.8
                                    similarity_rate_endg.append(similarity_rate[num]) #Âêå„ÅòÁõÆÊ®ô„ÇíÊåÅ„Å£„Å¶„Çã‰∫∫„Åü„Å°„ÅÆÈÖçÂàóÁï™Âè∑„ÅåÂÖ•„Å£„Å¶„Çã
                            print('6', similarity_rate_endg)
                        
                        
                        
                        
                            #LDA 
                            other_user_txt_bbs = []
                            other_user_act_bbs = []
                            for num in similarity_rate_endg:
                                other_user_ip = all_personality_record_pre[num][1]
                                other_user_dairy = np.array(database.l2_dairy_show(other_user_ip))
                        
                                mind = int(other_user_dairy[0][2]) #1„Å§ÁõÆ„ÇíÂèñÂæó
                                print('7-1', other_user_dairy)
                                print('7-2', mind)
                        
                                for next_mind in other_user_dairy: #2„Å§ÁõÆ„Åã„Çâ„Åó„Åü„ÅÑ„Åë„Å©„ÄÅ‰ΩôË®à„Å™„Ç≥„Éº„Éâ„ÅåÂ¢ó„Åà„Çã„ÅÆ„Åß„Çπ„É´„Éº
                                    if int(next_mind[2]) > mind: #üåüÊú¨Áï™„ÅØ>=„Åß„ÅØ„Å™„Åè>„ÅÆ„Åø
                        
                                        x_day = (next_mind[4] - mind_datetime).days #Êï∞ÂÄ§‰∏äÊòáÂâçÊó•-Êï∞ÂÄ§‰∏äÊòáÊó•„ÄÇ‰ΩïÊó•„Åã„ÅÆ„ÅøÂèñÂæó„ÄÅÊôÇÈñìÂàá„ÇäÊç®„Å¶ 
                                        print('7-3', x_day)
                                        print('7-4', next_mind[4])
                                        print('7-5', mind_datetime)
                        
                                        for day in range(-x_day):
                                            add_day = mind_datetime + datetime.timedelta(days = -day) #Êï∞ÂÄ§‰∏äÊòáÂâçÊó•„Åã„ÇâÔºëÊó•„Åö„Å§ËøΩÂä† üåüÊú¨Áï™„Åß„ÅØ„Åì„Å£„Å°
                                            add_day = add_day.strftime('%Y-%m-%d') #ÊôÇÂàª„ÇíÊç®„Å¶„Çã üåüÊú¨Áï™„Åß„ÅØ„Åì„Å£„Å°
                                            # add_day = '2021-01-07'
                                            print('7-6', add_day)
                        
                                            #Êé≤Á§∫Êùø„Åß„ÅÆÁô∫Ë®ÄÂõûÂèé
                                            other_user_txt_bbs_pre = np.array(database.l3_bbs_txt_show_date(add_day))
                                            print('8', other_user_txt_bbs_pre)
                                            if len(other_user_txt_bbs_pre) != 0: #Êé≤Á§∫Êùø„Åß„ÅÆÁô∫Ë®Ä„Åå„ÅÇ„Å£„Åü„Çâ
                                                for num in other_user_txt_bbs_pre:
                                                    other_user_txt_bbs.append(num[2]) #Êé≤Á§∫Êùø„Åß„ÅÆÁô∫Ë®Ä„ÇíÂõûÂèé
                        
                                            #Êé≤Á§∫Êùø„Åß„ÅÆ„Ç¢„ÇØ„Ç∑„Éß„É≥ÂõûÂèé „Ç¢„ÇØ„Ç∑„Éß„É≥‚Üí„É™„Ç¢„ÇØ„Ç∑„Éß„É≥„Åó„Åüid‚ÜíÊé≤Á§∫Êùø„Åß„ÅÆÁô∫Ë®Äid
                                            other_user_act_bbs_pre = np.array(database.l3_bbs_act_show_date(add_day))
                                            print('9', other_user_act_bbs_pre)
                        
                                            if len(other_user_act_bbs_pre) > 0: #Êé≤Á§∫Êùø„Åß„ÅÆË°åÂãï„Åå„ÅÇ„Å£„Åü„Çâ
                                                print('9-1', other_user_act_bbs_pre)
                                                for num in other_user_act_bbs_pre:
                                                    print('9-2', num)
                                                    bbs_txt_pre = np.array(database.l3_bbs_txt_show_id(num[2]))
                                                    print('9-3', bbs_txt_pre)
                                                    bbs_txt = np.ravel(bbs_txt_pre)
                                                    try:
                                                        other_user_act_bbs.append(bbs_txt[2]) #Êé≤Á§∫Êùø„Åß„ÅÆ„Ç¢„ÇØ„Ç∑„Éß„É≥„ÇíÂõûÂèé
                                                    except IndexError:
                                                        pass
                                                    print('10', other_user_act_bbs)
                        
                                    mind_datetime = next_mind[4]
                                    mind = int(next_mind[2])
                        
                                break #üåüÊú¨Áï™„Åß„ÅØ„Åì„Çå„ÇíËß£Èô§ Â§ßÈáè„Å´‰ºº„Å¶„Çã‰∫∫„Åå„ÅÑ„Çã„ÅÆ„ÅßÊºîÁÆó„ÅåÈï∑„Åè„Å™„Çã„ÅÆ„Åß
                            
                            if other_user_act_bbs == []:
                                ai_txt = 'sorry, we can not any suggestion'
                            else:
                                act_bbs = word_cut(other_user_act_bbs)
                                txt_bbs = word_cut(other_user_txt_bbs)
                                act_txt_bbs_pre = act_bbs + txt_bbs
                        
                                act_txt_bbs = ''
                                for bbs in act_txt_bbs_pre:
                                    act_txt_bbs = bbs +' '+ act_txt_bbs #today making great fuck day app today making great day app
                        
                        
                                ai_txt = LSTM_RNN.make_sentense(act_txt_bbs)
                                # print(ai_txt)
                        
                            return ai_txt
                      </textarea>
                    </li>
                </ul>
              </li>
        </ul>

    </div>
</div>


<!-- „ÉÅ„Çß„ÉÉ„ÇØ„Éú„ÉÉ„ÇØ„Çπ‰øùÊåÅ -->
<script> 
    var targets = document.querySelectorAll('.question_checkbox');
    var checkboxClick = function(){
        var self = this;
        sessionStorage.setItem('input[data-question="' + self.getAttribute('data-question') + '"]', self.checked);
    };
    Array.prototype.forEach.call(targets, function(e){
        e.addEventListener('click', checkboxClick)
    })

    var addSessionStorage = function() {
        var session = sessionStorage;
        Object.keys(session).forEach(function(key){
            if(key.indexOf('data-question') !== -1 && this[key] === 'true' && document.querySelector(key) !== null) {
                document.querySelector(key).checked = true;
            }
        }, session)
    }

    window.addEventListener('load', addSessionStorage);
</script>

{% endblock %}


