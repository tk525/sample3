import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
from kivy.app import App
from kivy.uix.screenmanager import Screen
from kivy.lang import Builder
from kivy.uix.image import Image
from kivy.graphics.texture import Texture
from kivy.clock import Clock
from kivy.uix.boxlayout import BoxLayout
from kivy.uix.behaviors import ButtonBehavior
from kivy.properties import ObjectProperty
from kivy.uix.label import Label
from kivy.uix.widget import Widget
from kivy.properties import StringProperty
import cv2
import math

import pyaudio
import wave
import time
import sys

import database, l1_login



Builder.load_file("main.kv")



#ãƒãƒ£ãƒƒãƒˆ
class SMS_user(Screen):
    def send_txt(self):
        self.ids.rv.data.append({'text': self.ids.txt.text, 'halign': 'left'})
        self.ids.txt.text = ''

# class SMS_mher(Screen):
#     def receive_txt(self):
#         self.ids.rv.data.append({'text': self.ids.txt.text, 'halign': 'right', })
#         self.ids.txt.text = ''

class Chat_user(App):
    def build(self):
        return SMS_user()
# class Chat_mher(App):
#     def build(self):
#         return SMS_mher()



#ãƒ“ãƒ‡ã‚ªãƒãƒ£ãƒƒãƒˆ
class VChat(Widget):

    def camera(self):

        time = 1            # è¨ˆæ¸¬æ™‚é–“[s]
        samplerate = 44100  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ
        fs = 512 * 2           # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚º
        index = 0           # ãƒã‚¤ã‚¯ã®ãƒãƒ£ãƒ³ãƒãƒ«æŒ‡æ¨™

        pa = pyaudio.PyAudio()
        data = []
        dt = 1 / samplerate


        # 0ç•ªç›®ã®ã‚«ãƒ¡ãƒ©ã«æ¥ç¶š
        self.capture = cv2.VideoCapture(0)

        # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®é–‹å§‹
        stream = pa.open(format=pyaudio.paInt16, channels=1, rate=samplerate,
                        input=True, input_device_index=index, frames_per_buffer=fs)

        # æç”»ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒ«ã‚’è¨­å®š
        while(True):
    
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚ºæ¯ã«éŸ³å£°ã‚’éŒ²éŸ³ã—ã¦ã„ããƒ«ãƒ¼ãƒ—
            for i in range(int(((time / dt) / fs))):
                frame = stream.read(fs)
                data.append(frame)


            ret, frame = self.capture.read()

            x = math.floor(frame.shape[0]/5)
            y = math.floor(frame.shape[1]/5)

            cam = cv2.rectangle(frame,
                (20, 20), #å·¦ä¸Šã‹ã‚‰ä½•pxç›®ã‹
                (y, x), #æ¨ª,ç¸¦
                (255, 0, 0), #(255, 0, 0) ã‚«ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰
                ) #å¡—ã‚Šã¤ã¶ã—
            # cam = np.hstack((frame, test_img))

            cv2.imshow('VChat',cam)

            # ã“ã“ã‹ã‚‰ã‚°ãƒ©ãƒ•æç”»
            voice_pre = np.arange(0, fs * (i+1) * (1 / samplerate), 1 / samplerate)
            print(voice_pre) #ã¨ã‚Šã‚ãˆãš


            if cv2.waitKey(1) & 0xFF == ord('q'):
                break


        self.capture.release()
        cv2.destroyAllWindows()

        # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®çµ‚äº†
        stream.stop_stream()
        stream.close()
        pa.terminate()
    

class VChatApp(App):
    def __init__(self, **kwargs):
        super(VChatApp, self).__init__(**kwargs)
        self.title = 'VCã•ã‚“ã·ã‚‹ã†'

    def build(self):
        return VChat()



#TEL
class Tel(Widget):

    def tel_record(self):

        time = 1            # è¨ˆæ¸¬æ™‚é–“[s]
        samplerate = 44100  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ
        fs = 1024           # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚º
        index = 0           # ãƒã‚¤ã‚¯ã®ãƒãƒ£ãƒ³ãƒãƒ«æŒ‡æ¨™

        wfm, i = CameraPreview.record(time, samplerate, fs, index)
        voice_pre = np.arange(0, fs * (i+1) * (1 / samplerate), 1 / samplerate)

        print(voice_pre)
        # plt.rcParams['font.size'] = 14
        # plt.rcParams['font.family'] = 'Times New Roman'
        
        # # ç›®ç››ã‚’å†…å´ã«ã™ã‚‹ã€‚
        # plt.rcParams['xtick.direction'] = 'in'
        # plt.rcParams['ytick.direction'] = 'in'
            
        # # ã‚°ãƒ©ãƒ•ã®ä¸Šä¸‹å·¦å³ã«ç›®ç››ç·šã‚’ä»˜ã‘ã‚‹ã€‚
        # fig = plt.figure()
        # ax1 = fig.add_subplot(111)
        # ax1.yaxis.set_ticks_position('both')
        # ax1.xaxis.set_ticks_position('both')
            
        # # è»¸ã®ãƒ©ãƒ™ãƒ«ã‚’è¨­å®šã™ã‚‹ã€‚
        # ax1.set_xlabel('Time [s]')
        # ax1.set_ylabel('Sound pressure [Pa]')
            
        # # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ãƒƒãƒˆã®æº–å‚™ã¨ã¨ã‚‚ã«ã€ãƒ©ãƒ™ãƒ«ã¨ç·šã®å¤ªã•ã€å‡¡ä¾‹ã®è¨­ç½®ã‚’è¡Œã†ã€‚
        # ax1.plot(t, wfm, label='signal', lw=1)
            
        # fig.tight_layout()
            
        # # ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã™ã‚‹ã€‚
        # plt.show()
        # plt.close()


class TelApp(App):
    def __init__(self, **kwargs):
        super(TelApp, self).__init__(**kwargs)
        self.title = 'Tã•ã‚“ã·ã‚‹ã†'

    def build(self):
        return Tel()







#0:ãƒãƒ£ãƒƒãƒˆ 1:ãƒ“ãƒ‡ã‚ªé›»è©± 2:é›»è©±ã®ã¿
order = 0

ip = l1_login.get_ip().pop()
memo_from_mc = 'she is fine.'

mher = 2

if mher >= 1: #ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã®å¾…æ©ŸãŒ1ä»¥ä¸Šã®å ´åˆ


    # #ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æƒ…å ±é–‹ç¤º #ğŸŒŸæœ¬ç•ªã§ã¯DBé–¢é€£ã®æ“ä½œã‚’èµ·å‹•ã™ã‚‹
    # ip = l1_login.get_ip().pop()


    # #ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŠ•ç¨¿ã—ãŸå…¨ãƒ†ã‚­ã‚¹ãƒˆã¨ã‚¹ã‚³ã‚¢
    # user_score_and_text_pre = database.l1_user_show(ip)
    # if user_score_and_text_pre is not None:
    #     user_score_and_text = user_score_and_text_pre.pop()


    # #ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ€§æ ¼ç‰¹å¾´
    # user_personality_pre = database.l2_personality_last_record(ip)
    # if user_personality_pre is not None:
    #     user_personality_pre = user_personality_pre.pop()
    #     user_personality_pre = user_personality_pre[2].translate(str.maketrans({'[': '', ']': '', ' ': ''})) #101110001110101010010001101
    #     personality_name = np.array(pd.read_excel('/Users/takipon/Desktop/dprapp/sample.xlsx', index_col=0, header=0, sheet_name='personality_x2').columns)

    #     user_personality = []
    #     for num in range(len(user_personality_pre)):
    #         if user_personality_pre[num] == '1':
    #             user_personality.append(personality_name[num]) #['çœŸé¢ç›®Seriousness', 'ã‚µãƒœã‚Œãªã„Cannot slack


    # #ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¨­å®šã—ãŸç›®æ¨™
    # user_endg_and_tasks_pre = database.l2_endg_show(ip)
    # if user_endg_and_tasks_pre is not None:
    #     user_endg_and_tasks = user_endg_and_tasks_pre.pop()


    # #ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒBBSã«æŠ•ç¨¿ã—ãŸãƒ†ã‚­ã‚¹ãƒˆ
    # user_bbs_txt_pre = np.array(database.l3_bbs_txt_show_id(ip))
    # if user_bbs_txt_pre is not None:
    #     user_bbs_txt = user_bbs_txt_pre


    # #ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒBBSã§ã„ã„ã­ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã®ã¿
    # user_bbs_act_pre = np.array(database.l3_bbs_act_show_id(ip))
    # if user_bbs_act_pre is not None:
    #     user_bbs_act = []
    #     for bbs_act in user_bbs_act_pre:
    #         bbs_act_id = bbs_act[2]
    #         bbs_act_pre = database.l3_bbs_txt_show_post_id(bbs_act_id)
    #         user_bbs_act.append(bbs_act_pre.pop()[2]) #ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã®ã¿å–å¾—


    if order == 0: #ãƒãƒ£ãƒƒãƒˆ
        print('ãƒãƒ£ãƒƒãƒˆ')
        Chat_user().run()
    #     Chat_mher().run()

    if order == 1: #ãƒ“ãƒ‡ã‚ªãƒãƒ£ãƒƒãƒˆ
        print('ãƒ“ãƒ‡ã‚ªãƒãƒ£ãƒƒãƒˆ')
        # CameraPreview()
        VChatApp().run()

    if order == 2: #TEL
        print('TEL')
        TelApp().run()

    database.l3_mc_insert(ip, memo_from_mc)    
    
else:
    print('ç¾åœ¨æ··ã¿åˆã£ã¦ãŠã‚Šã¾ã™')


